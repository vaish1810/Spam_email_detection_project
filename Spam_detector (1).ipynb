{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM E-MAIL DETECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Email spam detection is a classification problem. Some algorithms like Naive Bayes Classifier, Decision Trees work well \n",
    "for spam detection. Algorithms like KNN, Linear Regression don’t really work well due to inherent disadvantages \n",
    "such as curse of dimensionality.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach -  Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes is the easiest classification algorithm (fast to build, regularly used for spam detection). \n",
    "It is a popular (baseline) method for text categorization, the problem of judging documents as\n",
    "belonging to one category or the other (such as spam or legitimate, sports or politics, etc.) \n",
    "with word frequencies as the features.**\n",
    "\n",
    "**Why use Naive Bayes?**\n",
    "\n",
    "NB is very simple, easy to implement and fast because essentially you’re just doing a bunch of counts.\n",
    "\n",
    "If the NB conditional independence assumption holds, then it will converge quicker than \n",
    "discriminative models like logistic regression.\n",
    "NB needs works well even with less sample data.\n",
    "\n",
    "NB is highly scalable. It scales linearly with the number of predictors and data points.\n",
    "\n",
    "NB can be used for both binary and multi-class classification problems and handles continuous and discrete data [2].\n",
    "\n",
    "NB is not sensitive to irrelevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1 = IMPORTING LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step2 = LOADING DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>EmailText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                          EmailText\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"spam.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check number of rows & columns in our dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Label', 'EmailText'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the columns in our dataset\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this step would drop all the duplicate values in our dataset\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now after deleting all the duplicacy lets again check no .of rows & columns left in our data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label        0\n",
       "EmailText    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for NAN values in the dataset\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**this function would remove all the punctuations,stopwords & would return clean text words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function would remove all the punctuations,stopwords & would return clean text words\n",
    "def process_text(text):\n",
    "    nopunc=[char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    clean_words = [words for words in nopunc.split() if words.lower() not in stopwords.words('english')]\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization(a list of tokens also known as lemmas)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
       "Name: EmailText, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show tokenization(a list of tokens also known as lemmas)\n",
    "data['EmailText'].head().apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world hello world test\n",
      "\n",
      "  (0, 0)\t2\n",
      "  (0, 4)\t2\n",
      "  (0, 3)\t1\n",
      "  (1, 1)\t2\n",
      "  (1, 2)\t2\n",
      "\n",
      "(2, 5)\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "message4 = \"hello world hello world test\"\n",
    "message5 = \"play stop play stop\"\n",
    "print(message4)\n",
    "print()\n",
    "\n",
    "# convert the text to a matrix of token counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "a = CountVectorizer(analyzer=process_text).fit_transform([[message4],[message5]])\n",
    "print(a)\n",
    "print()\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a collection of text into a matrix of tokens\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "message_bag = CountVectorizer(analyzer=process_text).fit_transform(data['EmailText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the data into 80% training & 20% testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 80% training & 20% testing\n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test = train_test_split(message_bag,data['Label'],test_size=0.20,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 11304)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_bag.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create & train the NaiveBayes Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create & train the NaiveBayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n",
      "\n",
      "['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "# print the predictions\n",
    "print(classifier.predict(x_train))\n",
    "print()\n",
    "# print the actual values\n",
    "print(y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model on training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      3631\n",
      "        spam       0.98      0.98      0.98       504\n",
      "\n",
      "    accuracy                           1.00      4135\n",
      "   macro avg       0.99      0.99      0.99      4135\n",
      "weighted avg       1.00      1.00      1.00      4135\n",
      "\n",
      "\n",
      "Confusion matrix : \n",
      " [[3623    8]\n",
      " [  11  493]]\n",
      "\n",
      "Accuracy:\n",
      " 0.9954050785973397\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "pred = classifier.predict(x_train)\n",
    "print(classification_report(y_train,pred))\n",
    "print()\n",
    "print(\"Confusion matrix : \\n\",confusion_matrix(y_train,pred))\n",
    "print()\n",
    "print(\"Accuracy:\\n\",accuracy_score(y_train,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n",
      "\n",
      "['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(x_test))\n",
    "print()\n",
    "print(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model on testing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.96      0.97       885\n",
      "        spam       0.80      0.93      0.86       149\n",
      "\n",
      "    accuracy                           0.96      1034\n",
      "   macro avg       0.89      0.94      0.92      1034\n",
      "weighted avg       0.96      0.96      0.96      1034\n",
      "\n",
      "\n",
      "Confusion matrix : \n",
      " [[850  35]\n",
      " [ 11 138]]\n",
      "\n",
      "Accuracy:\n",
      " 0.9555125725338491\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "pred = classifier.predict(x_test)\n",
    "print(classification_report(y_test,pred))\n",
    "print()\n",
    "print(\"Confusion matrix : \\n\",confusion_matrix(y_test,pred))\n",
    "print()\n",
    "print(\"Accuracy:\\n\",accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The accuracy of my email spam detection model on training data is 99.5% & on testing data is 95.5%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
